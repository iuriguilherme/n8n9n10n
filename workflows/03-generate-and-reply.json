{
  "name": "03 - Generate and Reply",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "generate-and-reply",
        "responseMode": "onReceived",
        "options": {}
      },
      "id": "webhook-generate",
      "name": "Generate & Reply Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [240, 300]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT message_role, message_content, message_timestamp FROM agent_memory WHERE agent_name = '{{$json.agent_name}}' AND chat_id = {{$json.raw.message.chat.id}} AND (expires_at IS NULL OR expires_at > NOW()) ORDER BY message_timestamp DESC LIMIT 20;",
        "additionalFields": {}
      },
      "id": "get-memory",
      "name": "Get Agent Memory",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [520, 300],
      "credentials": { "postgres": { "id": "1", "name": "Postgres account" } }
    },
    {
      "parameters": {
        "jsCode": "// Build conversation history\nconst incoming = $input.first().json;\nconst memories = $input.all()[1].json; // results from memory node\nconst history = [];\nif (Array.isArray(memories)) {\n  for (let i = memories.length -1; i >=0; i--) {\n    const m = memories[i];\n    history.push({ role: m.message_role, content: m.message_content });\n  }\n}\nhistory.push({ role: 'user', content: incoming.raw.message.text });\nreturn [{ json: { agent_name: incoming.agent_name, agent_personality: incoming.agent_personality, agent_system_prompt: incoming.agent_system_prompt, chat_id: incoming.raw.message.chat.id, conversation_history: history } }];"
      },
      "id": "build-history",
      "name": "Build Conversation History",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [760, 300]
    },
    {
      "parameters": {
        "resource": "chat",
        "operation": "create",
        "model": "={{$env.LLM_MODEL || 'gpt-3.5-turbo'}}",
        "messages": {
          "values": [
            { "role": "system", "content": "={{$json.agent_system_prompt}}" },
            { "role": "user", "content": "={{JSON.stringify($json.conversation_history)}}" }
          ]
        },
        "options": { "temperature": 0.7, "maxTokens": 500 }
      },
      "id": "call-llm",
      "name": "Call LLM (OpenAI)",
      "type": "n8n-nodes-base.openAi",
      "typeVersion": 1,
      "position": [1000, 300],
      "credentials": { "openAiApi": { "id": "2", "name": "OpenAI account" } }
    },
    {
      "parameters": {
        "jsCode": "const item = $input.first();\nconst content = item.json.choices && item.json.choices[0] && item.json.choices[0].message && item.json.choices[0].message.content ? item.json.choices[0].message.content : (item.json.text || '');\nreturn [{ json: { llm_response: content, prompt_tokens: item.json.usage && item.json.usage.prompt_tokens || 0, completion_tokens: item.json.usage && item.json.usage.completion_tokens || 0, agent_name: $json.agent_name, chat_id: $json.chat_id } }];"
      },
      "id": "extract-response",
      "name": "Extract LLM Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1240, 300]
    },
    {
      "parameters": {
        "resource": "message",
        "operation": "sendMessage",
        "chatId": "={{$json.chat_id}}",
        "text": "={{$json.llm_response}}",
        "additionalFields": {}
      },
      "id": "send-telegram",
      "name": "Send Telegram Reply",
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1,
      "position": [1480, 300],
      "credentials": { "telegramApi": { "id": "3", "name": "Telegram account" } }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO agent_responses (update_id, agent_name, agent_personality, response_text, llm_model, prompt_tokens, completion_tokens) VALUES ((SELECT id FROM telegram_updates WHERE id = {{$json.storedId}} LIMIT 1), '{{$json.agent_name}}', '{{$json.agent_personality}}', '{{$json.llm_response}}', '{{$env.LLM_MODEL}}', {{$json.prompt_tokens}}, {{$json.completion_tokens}}) RETURNING id;",
        "additionalFields": {}
      },
      "id": "store-response",
      "name": "Store Agent Response",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [1240, 520],
      "credentials": { "postgres": { "id": "1", "name": "Postgres account" } }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO agent_memory (agent_name, chat_id, message_role, message_content, message_timestamp, expires_at) VALUES ('{{$json.agent_name}}', {{$json.chat_id}}, 'assistant', '{{$json.llm_response}}', NOW(), NOW() + INTERVAL '1 hour');",
        "additionalFields": {}
      },
      "id": "update-memory",
      "name": "Update Agent Memory",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2,
      "position": [1480, 520],
      "credentials": { "postgres": { "id": "1", "name": "Postgres account" } }
    }
  ],
  "connections": {
    "Generate & Reply Webhook": { "main": [ [ { "node": "Get Agent Memory", "type": "main", "index": 0 } ] ] },
    "Get Agent Memory": { "main": [ [ { "node": "Build Conversation History", "type": "main", "index": 0 } ] ] },
    "Build Conversation History": { "main": [ [ { "node": "Call LLM (OpenAI)", "type": "main", "index": 0 } ] ] },
    "Call LLM (OpenAI)": { "main": [ [ { "node": "Extract LLM Response", "type": "main", "index": 0 } ] ] },
    "Extract LLM Response": { "main": [ [ { "node": "Send Telegram Reply", "type": "main", "index": 0 } ], [ { "node": "Store Agent Response", "type": "main", "index": 0 } ], [ { "node": "Update Agent Memory", "type": "main", "index": 0 } ] ] }
  },
  "active": false,
  "settings": {},
  "versionId": "1",
  "id": "3",
  "meta": { "instanceId": "n8n-local" }
}
